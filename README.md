# Atividade CIFAR-100
ğŸ“Š ANÃLISE DOS RESULTADOS - CIFAR-100


## ObservaÃ§Ãµes sobre o Treinamento com CIFAR-100:

A LeNet-5 adaptada para CIFAR-100 (com in_channels=3 e 100 classes de saÃ­da) foi treinada por
24 Ã©pocas, demonstrando progressÃ£o consistente mas limitada devido Ã  complexidade do dataset.

*Resultados AlcanÃ§ados:*
- AcurÃ¡cia inicial (Epoch 1): Train 3.57% | Test 4.68%
- AcurÃ¡cia final (Epoch 24): Train 25.48% | Test *23.46%*
- Loss final: Train 3.0806 | Test 3.2118
- ProgressÃ£o total: ganho de ~20% em acurÃ¡cia ao longo de 24 Ã©pocas

Essa acurÃ¡cia de 23.46% Ã© condizente com o esperado para a arquitetura LeNet-5 aplicada ao
CIFAR-100. O dataset CIFAR-100 Ã© significativamente mais desafiador que o CIFAR-10 (que atinge
65-70% com LeNet-5), devido ao nÃºmero 10x maior de classes (100 vs 10).

As curvas de loss e accuracy revelam:
- *ConvergÃªncia gradual*: reduÃ§Ã£o consistente do loss ao longo das Ã©pocas
- *Overfitting moderado*: pequena diferenÃ§a entre train loss (3.08) e test loss (3.21)
- *Aprendizado contÃ­nuo*: acurÃ¡cia de teste ainda estava melhorando na Ã©poca 24
- *LimitaÃ§Ã£o arquitetural*: LeNet-5 tem apenas 69,656 parÃ¢metros, insuficientes para
  capturar toda a complexidade de 100 classes distintas

## AnÃ¡lise dos Feature Maps:

A visualizaÃ§Ã£o dos feature maps revela o processamento hierÃ¡rquico da informaÃ§Ã£o:

- *conv1 + relu1*: Os 6 filtros da primeira camada (28x28) detectam caracterÃ­sticas de baixo
  nÃ­vel como bordas horizontais, verticais, diagonais e gradientes de cor. Com 100 classes,
  a rede precisa identificar detalhes sutis que diferenciam categorias similares.

- *pool1*: O max pooling (2x2) reduz de 28x28 para 14x14, mantendo as caracterÃ­sticas mais
  salientes e criando invariÃ¢ncia posicional parcial, essencial para robustez.

- *conv2 + relu2*: Os 16 filtros da segunda camada (10x10) combinam features de conv1 para
  detectar padrÃµes mais complexos e abstratos. Observa-se ativaÃ§Ã£o seletiva para estruturas
  especÃ­ficas das imagens.

- *pool2*: Segunda reduÃ§Ã£o dimensional (14x14 -> 5x5), consolidando representaÃ§Ãµes abstratas
  antes do classificador.

A visualizaÃ§Ã£o confirma que a LeNet-5, embora simples, consegue extrair features relevantes.
PorÃ©m, para 100 classes, arquiteturas mais profundas (VGG, ResNet, EfficientNet) seriam mais
adequadas, pois oferecem maior capacidade de representaÃ§Ã£o (milhÃµes de parÃ¢metros vs 69k).

## ComparaÃ§Ã£o e Contexto:

- *CIFAR-10 com LeNet-5*: ~65-70% de acurÃ¡cia (esperado)
- *CIFAR-100 com LeNet-5*: ~23.46% de acurÃ¡cia (nosso resultado)
- *CIFAR-100 com ResNet-18*: ~75-80% de acurÃ¡cia (benchmark comum)
- *CIFAR-100 State-of-the-art*: >95% de acurÃ¡cia (redes modernas)

A diferenÃ§a de 3x na dificuldade (70% -> 23%) ao aumentar de 10 para 100 classes demonstra
o desafio de classificaÃ§Ã£o granular com arquiteturas simples.

## ConclusÃ£o:

O experimento demonstrou com sucesso:

âœ… ImplementaÃ§Ã£o de CNN (LeNet-5) adaptada para CIFAR-100

âœ… Treinamento completo de 24 Ã©pocas com registro de mÃ©tricas

âœ… ImplementaÃ§Ã£o de hooks para captura de ativaÃ§Ãµes intermediÃ¡rias

âœ… VisualizaÃ§Ã£o de feature maps de todas as 6 camadas

âœ… AnÃ¡lise quantitativa e qualitativa dos resultados

Os resultados confirmam que a complexidade do CIFAR-100 (100 classes) exige arquiteturas mais
sofisticadas para atingir acurÃ¡cias superiores a 70-80%. A LeNet-5, com sua simplicidade,
atingiu 23.46% - um resultado razoÃ¡vel considerando suas limitaÃ§Ãµes arquiteturais.


âœ… ATIVIDADE CONCLUÃDA - TODOS OS REQUISITOSÂ ATENDIDOS
